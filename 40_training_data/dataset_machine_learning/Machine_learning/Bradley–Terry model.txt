The Bradley–Terry model is a probability model for the outcome of pairwise comparisons between items, teams, or objects. Given a pair of items  and  drawn from some population, it estimates the probability that the pairwise comparison  turns out true, as

{{NumBlk|:|\Pr(i > j) = \frac{p_i}{p_i + p_j}|}}

where  is a positive real-valued score assigned to individual . The comparison  can be read as " is preferred to ", " ranks higher than ", or " beats ", depending on the application.

For example,  might represent the skill of a team in a sports tournament and \Pr(i>j) the probability that  wins a game against . who presented it in 1952, although it had already been studied by Ernst Zermelo in the 1920s. Applications of the model include the ranking of competitors in sports, chess, and other competitions, the ranking of products in paired comparison surveys of consumer choice, analysis of dominance hierarchies within animal and human communities, ranking of journals, ranking of AI models, and estimation of the relevance of documents in machine-learned search engines.

Definition

The Bradley–Terry model can be parametrized in various ways. Equation () is perhaps the most common, but there are a number of others.  Bradley and Terry themselves defined exponential score functions p_i = e^{\beta_i}, so that

\Pr(i > j) = \frac{e^{\beta_i}}{e^{\beta_i} + e^{\beta_j}} = \frac{1}{1 + e^{\beta_j-\beta_i}}.

Alternatively, one can use a logit, such that which models ranking N items. In the same notation as BT model:

\Pr(y_1 > \cdots > y_N) = \prod_{i=1}^N \frac{p_{y_i}}{\sum_{k=i}^N p_{y_k}} = \frac{p_{y_1}}{p_{y_1} + \dots + p_{y_N}}\frac{p_{y_2}}{p_{y_2} + \cdots + p_{y_N}} \cdots \frac{p_{y_N}}{p_{y_N}}

The factor with i=N is always just unity, so for N=2 this reduces to \Pr(y_1 > y_2) = p_{y_1}/(p_{y_1} + p_{y_2}).

This can be imagined as drawing from an urn with replacement. The urn contains balls colored in proportion to p_1, p_2, \dots, p_N, and one draws from the urn with replacement. If a ball has a new color, then that ball is placed as the next-ranked ball. Otherwise, if the ball has a color already drawn, then it is discarded.

Given the proportions p_1, p_2, \dots, p_N, the PL model can be sampled by the "exponential race" method. One samples "radioactive decay times" from N "exponential clocks", that is, t_1 \sim \mathrm{Exp}(p_1), \dots, t_N \sim \mathrm{Exp}(p_N). Then one ranks the items according to the order in which they decayed. In this interpretation, it is immediately clear that the PL model satisfies Luce's choice axiom (from the same Luce). Therefore, for any two y, z, \Pr(y > z) = \frac{p_y}{p_y + p_z} reduces to the BT model, and in general, for any subset y_1, \dots, y_M of the choices,

\Pr(y_1 > \cdots > y_N) = \frac{p_{y_1}}{p_{y_1} + \cdots + p_{y_M}}\frac{p_{y_2}}{p_{y_2} + \cdots + p_{y_M}} \cdots \frac{p_{y_M}}{p_{y_M}}

reduces to a smaller PL model with the same parameters.

Inference

The most common application of the Bradley–Terry model is to infer the values of the parameters p_i given an observed set of outcomes i>j, such as wins and losses in a competition.  The simplest way to estimate the parameters is by maximum likelihood estimation, i.e., by maximizing the likelihood of the observed outcomes given the model and parameter values.

Suppose we know the outcomes of a set of pairwise competitions between a certain group of individuals, and let  be the number of times individual  beats individual .  Then the likelihood of this set of outcomes within the Bradley–Terry model is \prod_{ij} [\Pr(i>j)]^{w_{ij}} and the log-likelihood of the parameter vector {{math|p  [p1, ..., pn]}} is  It is, however, slow to converge.  More recently it has been pointed out that equation () can also be rearranged as

p_i = \frac{\sum_{j} w_{ij} p_j/(p_i+p_j)}{\sum_{j} w_{ji}/(p_i+p_j)},

which can be solved by iterating

{{NumBlk|:|p_i' = \frac{\sum_{j} w_{ij} p_j/(p_i+p_j)}{\sum_j w_{ji}/(p_i+p_j)},|}}

again normalizing after every round of updates using equation (). This iteration gives identical results to the one in () but converges much faster and hence is normally preferred over (). attempts to extend the standard Bradley–Terry model for crowdsourced settings while reducing the number of comparisons needed by taking into account the reliability of each judge. In particular, it identifies and excludes judges presumed to be spammers (selecting choices at random) or malicious (selecting always the wrong choice). In a crowdsourced task of ranking documents by reading difficulty with 624 judges contributing up to 40 pairwise comparisons each, Crowd-BT was shown to outperform both standard Bradley–Terry as well as ranking system TrueSkill. It has been recommended for use when quality results are valued over efficiency and the number of comparisons is high.

See also

Elo rating system

Ordinal regression

Rasch model

Scale (social sciences)

Softmax function

Thurstonian model

References

Category:Machine learning

Category:Statistical models

Category:Logistic regression

Category:Regression models