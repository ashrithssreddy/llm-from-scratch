In data analysis, anomaly detection (also referred to as outlier detection and sometimes as novelty detection) is generally understood to be the identification of rare items, events or observations which deviate significantly from the majority of the data and do not conform to a well defined notion of normal behavior. or appear inconsistent with the remainder of that set of data.

Anomaly detection finds application in many domains including cybersecurity, medicine, machine vision, statistics, neuroscience, law enforcement and financial fraud to name only a few. Anomalies were initially searched for clear rejection or omission from the data to aid statistical analysis, for example to compute the mean or standard deviation. They were also removed to better predictions from models such as linear regression, and more recently their removal aids the performance of machine learning algorithms. However, in many applications anomalies themselves are of interest and are the observations most desirous in the entire data set, which need to be identified and separated from noise or irrelevant outliers.

Three broad categories of anomaly detection techniques exist.

By the late 1970s and early 1980s, the analysis of these logs was primarily used retrospectively to investigate incidents, as the volume of data made it impractical for real-time monitoring. The affordability of digital storage eventually led to audit logs being analyzed online, with specialized programs being developed to sift through the data. These programs, however, were typically run during off-peak hours due to their computational intensity.

Intrusion detection

Anomaly detection was proposed for intrusion detection systems (IDS) by Dorothy Denning in 1986. Anomaly detection for IDS is normally accomplished with thresholds and statistics, but can also be done with soft computing, and inductive learning. Types of features proposed by 1999 included profiles of users, workstations, networks, remote hosts, groups of users, and programs based on frequencies, means, variances, covariances, and standard deviations.  The counterpart of anomaly detection in intrusion detection is misuse detection.

Fintech fraud detection

Anomaly detection is vital in fintech for fraud prevention.

Preprocessing

Preprocessing data to remove anomalies can be an important step in data analysis, and is done for a number of reasons. Statistics such as the mean and standard deviation are more accurate after the removal of anomalies, and the visualisation of data can also be improved. In supervised learning, removing the anomalous data from the dataset often results in a statistically significant increase in accuracy.

Video surveillance

Anomaly detection has become increasingly vital in video surveillance to enhance security and safety. With the advent of deep learning technologies, methods using Convolutional Neural Networks (CNNs) and Simple Recurrent Units (SRUs) have shown significant promise in identifying unusual activities or behaviors in video data. Such pipelines are required for processing multiple video streams with low computational resources.

IT infrastructure

In IT infrastructure management, anomaly detection is crucial for ensuring the smooth operation and reliability of services. These are complex systems, composed of many interactive elements and large data quantities, requiring methods to process and reduce this data into a human and machine interpretable format. Techniques like the IT Infrastructure Library (ITIL) and monitoring frameworks are employed to track and manage system performance and user experience. It helps in identifying system failures and security breaches in complex networks of IoT devices. have introduced a multi-stage anomaly detection framework that improves upon traditional methods by incorporating spatial clustering, density-based clustering, and locality-sensitive hashing. This tailored approach is designed to better handle the vast and varied nature of IoT data, thereby enhancing security and operational reliability in smart infrastructure and industrial IoT systems. Martí et al. used a novel segmentation algorithm to analyze sensor data for real-time anomaly detection. Aljameel et al. propose an advanced machine learning-based model for detecting minor leaks in oil and gas pipelines, a task traditional methods may miss. The performance of methods usually depend on the data sets. For example, some may be suited to detecting local outliers, while others global, and methods have little systematic advantages over another when compared across many data sets. Almost all algorithms also require the setting of non-intuitive parameters critical for performance, and usually unknown before application. Some of the popular techniques are mentioned below and are broken down into categories:

Statistical

Parameter-free

Also referred to as frequency-based or counting-based, the simplest non-parametric anomaly detection method is to build a histogram with the training data or a set of known normal instances, and if a test point does not fall in any of the histogram bins mark it as anomalous, or assign an anomaly score to test data based on the height of the bin it falls in.

Parametric-based

Z-score,

Tukey's range test

Grubbs's test

Density

Density-based techniques (k-nearest neighbor, local outlier factor, isolation forests, and many more variations of this concept)

Subspace-base (SOD), correlation-based (COP) and tensor-based outlier detection for high-dimensional data

One-class support vector machines (OCSVM, SVDD)

Neural networks

Replicator neural networks, autoencoders, variational autoencoders, long short-term memory neural networks

Bayesian networks

Deep Learning

Simple Recurrent Units (SRUs): In time-series data, SRUs, a type of recurrent neural network, have been effectively used for anomaly detection by capturing temporal dependencies and sequence anomalies.

Foundation models: Since the advent of large-scale foundation models that have been used successfully on most downstream tasks, they have also been adapted for use in anomaly detection and segmentation. Methods utilizing pretrained foundation models include using the alignment of image and text embeddings (CLIP, etc.) for anomaly localization, while others may use the inpainting ability of generative image models for reconstruction-error based anomaly detection.

Cluster-based

Clustering: Cluster analysis-based outlier detection

Deviations from association rules and frequent itemsets

Fuzzy logic-based outlier detection

Ensembles

Ensemble techniques, using feature bagging, score normalization and different sources of diversity

Others

Histogram-based Outlier Score (HBOS) uses value histograms and assumes feature independence for fast predictions.

Anomaly detection in dynamic networks

Dynamic networks, such as those representing financial systems, social media interactions, and transportation infrastructure, are subject to constant change, making anomaly detection within them a complex task. Unlike static graphs, dynamic networks reflect evolving relationships and states, requiring adaptive techniques for anomaly detection.

Types of anomalies in dynamic networks

Community anomalies

Compression anomalies

Decomposition anomalies

Distance anomalies

Probabilistic model anomalies

Explainable anomaly detection

Many of the methods discussed above only yield an anomaly score prediction, which often can be explained to users as the point being in a region of low data density (or relatively low density compared to the neighbor's densities). In explainable artificial intelligence, the users demand methods with higher explainability. Some methods allow for more detailed explanations:

The Subspace Outlier Degree (SOD)

scikit-learn is an open-source Python library that contains some algorithms for unsupervised anomaly detection.

Wolfram Mathematica provides functionality for unsupervised anomaly detection across multiple data types

Datasets

Anomaly detection benchmark data repository with carefully chosen data sets of the Ludwig-Maximilians-Universität München; Mirror  at University of São Paulo.

ODDS – ODDS: A large collection of publicly available outlier detection datasets with ground truth in different domains.

Unsupervised Anomaly Detection Benchmark at Harvard Dataverse: Datasets for Unsupervised Anomaly Detection with ground truth.

KMASH Data Repository  at Research Data Australia having more than 12,000 anomaly detection datasets with ground truth.

See also

Change detection

Statistical process control

Novelty detection

Hierarchical temporal memory

References

Category:Data mining

Category:Machine learning

Category:Data security

Category:Statistical outliers

Category:Reliability engineering