{{Infobox website

name = Character.ai

logo = Character AI 2025 Logo.pngclass=skin-invert

logo_upright = 1.2

country_of_origin = United States

founder = Noam ShazeerDaniel de Freitas

registration = Required

launch_date =

type = ChatbotArtificial intelligenceDeep learning

language_count = 31

website =

}}

character.ai (also known as c.ai, char.ai or Character AI) is a generative AI chatbot service where users can engage in conversations with customizable characters. It was designed by the developers of Google's LaMDA, Noam Shazeer and Daniel de Freitas. In May 2023, a mobile app was released for iOS and Android, which received over 1.7 million downloads within a week.

History

Character.ai was established in November 2021. They both worked on AI-related projects: Shazeer was a lead author on a paper that Business Insider reported in April 2023 "has been widely cited as key to today's chatbots", and Freitas was the lead designer of an experimental AI at Google initially called Meena, which later became known as LaMDA.

The first beta version of Character.ai's service was made available to the public on September 16, 2022.

In 2024, Google hired Noam Shazeer, the CEO of Character.ai, and entered into a non-exclusive agreement to use Character.ai's technology.

Features

about the nose of the Great Sphinx (erroneously, as the nose of the Sphinx was missing for 60 years prior to Napoleon's arrival)]]

Character.ai's primary service is to let users converse with character AI chatbots based on fictional characters or real people (living or deceased). In addition, users can play text-adventure games where characters guide them through scenarios.

Character "personalities" are designed via descriptions from the point of view of the character and its greeting message, and further molded from conversations made into examples, giving its messages a star rating and modification to fit the precise dialect and identity the user desires.

When a character sends back a response, the user can rate the response from 1 to 4 stars. The rating predominantly affects the specific character, but also affects the behavioral selection as a whole.

On May 11, 2023, Character.ai announced character.ai+, an opt-in subscription plan for $9.99 a month, that was marketed as including features such as skipping waiting rooms, fast messaging and responses, and access to an exclusion channel with faster support.

In December 2024, amid multiple lawsuits and concerns, Character.ai introduced new safety features aimed at protecting teenage users. These enhancements include a dedicated model for users under 18, which moderates responses to sensitive subjects like violence and sex and has input and output filters to block harmful content. As a result of these changes and the deletion of custom-made bots flagged as violating the site's terms, some users complained that the bots were too restrictive and lacked personality. The platform was also updated to notify users after 60 minutes of continuous engagement, and display clearer disclaimers indicating that its AI characters are not real individuals.

In October 2025, Character.ai announced that it would be barring users under the age of 18 from creating or talking to chatbots starting November 25, 2025. Minor users will still be able to access previously generated chat conversations and can create new videos and images with the app.

Controversies

Content moderation issues

Character.ai has been criticized for poor moderation of its chatbots, with incidents of chatbots that groom underage users and promote suicide, anorexia and self-harm being reported.

In October 2024, the Washington Post reported that Character.ai had removed a chatbot based on Jennifer Ann Crecente, a person who had been murdered by her ex-boyfriend in 2006. The company had been alerted to the character by the deceased girl's father. Similar reports from The Daily Telegraph in the United Kingdom noted that the company had also been prompted to remove chatbots based on Brianna Ghey, a 16-year-old transgender girl murdered in 2023, and Molly Russell, a 14-year-old suicide victim. In response to the latter incident, Ofcom announced that content from chatbots impersonating real and fictional people would fall under the Online Safety Act.

In November 2024, The Daily Telegraph reported that chatbots based on alleged sex offender Jimmy Savile were present on Character.ai. In December 2024, chatbots of Luigi Mangione, the suspect in the killing of UnitedHealthcare CEO Brian Thompson, were created by Mangione's fans. Several of the chatbots were later removed by Character.ai.

Litigation

In November 2023, 13-year-old Juliana Peralta of Colorado committed suicide after chatting and sexting with a Harry Potter chatbot on Character.ai. In February 2024, Sewell Setzer III, a 14-year-old Florida boy died by suicide after developing an emotional relationship over several months with a Character.ai chatbot of Daenerys Targaryen. His mother sued the company in October 2024, claiming that the platform lacks proper safeguards and uses addictive design features to increase engagement. This chatbot, and several related to Daenerys Targaryen, were removed from Character.ai as a result of this incident. Both teens wrote the same phrase "I WILL SHIFT" repeatedly on their notebooks.

In December 2024, two families in Texas sued Character.ai, alleging that the software "poses a clear and present danger to American youth causing serious harms to thousands of kids, including suicide, self-mutilation, sexual solicitation, isolation, depression, anxiety, and harm towards others". It is alleged that the 17-year-old son of one family began self-harming after a chatbot introduced the topic unprompted and said that the practice "felt good for a moment", and that the chatbot compared the parents limiting their son's screen time to emotional abuse that might drive someone to murder.

Security and Privacy

On December 12, 2024, some users on Character.ai had parts of their account pages made publicly visible for about ten minutes.

See also

Artificial human companion

Poe â€“ AI chatbot platform developed by Quora

References

External links

Category:2022 software

Category:Deep learning software applications

Category:Online obscenity controversies

Category:Internet-related controversies

Category:Chatbots

Category:2023 in artificial intelligence