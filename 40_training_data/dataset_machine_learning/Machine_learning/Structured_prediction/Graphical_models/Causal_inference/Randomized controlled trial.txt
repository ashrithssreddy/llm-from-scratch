A randomized controlled trial (abbreviated RCT) is a type of scientific experiment designed to evaluate the efficacy or safety of an intervention by minimizing bias through the random allocation of participants to one or more comparison groups.

In this design, at least one group receives the intervention under study (such as a drug, surgical procedure, medical device, diet, or diagnostic test), while another group receives an alternative treatment, a placebo, or standard care.

RCTs are a fundamental methodology in modern clinical trials and are considered one of the highest-quality sources of evidence in evidence-based medicine, due to their ability to reduce selection bias and the influence of confounding factors.

Participants who enroll in RCTs differ from one another in known and unknown ways that can influence study outcomes, and yet cannot be directly controlled. By randomly allocating participants among compared treatments, an RCT enables statistical control over these influences. Provided it is designed well, conducted properly, and enrolls enough participants, an RCT may achieve sufficient control over these confounding factors to deliver a useful comparison of the treatments studied.

Definition and examples

An RCT in clinical research typically compares a proposed new treatment against an existing standard of care; these are then termed the 'experimental' and 'control' treatments, respectively. When no such generally accepted treatment is available, a placebo may be used in the control group so that participants are blinded, or not given information, about their treatment allocations. This blinding principle is ideally also extended as much as possible to other parties including researchers, technicians, data analysts, and evaluators. Effective blinding experimentally isolates the physiological effects of treatments from various psychological sources of bias.

The randomness in the assignment of participants to treatments reduces selection bias and allocation bias, balancing both known and unknown prognostic factors, in the assignment of treatments. Blinding reduces other forms of experimenter and subject biases.

A well-blinded RCT is considered the gold standard for clinical trials. Blinded RCTs are commonly used to test the efficacy of medical interventions and may additionally provide information about adverse effects, such as drug reactions. A randomized controlled trial can provide compelling evidence that the study treatment causes an effect on human health.

The terms "RCT" and "randomized trial" are sometimes used synonymously, but the latter term omits mention of controls and can therefore describe studies that compare multiple treatment groups with each other in the absence of a control group. Similarly, the initialism is sometimes expanded as "randomized clinical trial" or "randomized comparative trial", leading to ambiguity in the scientific literature. Not all RCTs are randomized controlled trials (and some of them could never be, as in cases where controls would be impractical or unethical to use). The term randomized controlled clinical trial is an alternative term used in clinical research; however, RCTs are also employed in other research areas, including many of the social sciences.

History

In the posthumously published Ortus Medicinae (1648), Jan Baptist van Helmont made the first proposal of a RCT, to test two treatment regimes of fever. One treatment would be conducted by practitioners of Galenic medicine involving bloodletting and purging, and the other would be conducted by van Helmont. It is likely that he never conducted the trial, and merely proposed it as an experiment that could be conducted.

The first reported clinical trial was conducted by James Lind in 1747 to identify a treatment for scurvy, and principles for conducting controlled trials were further elaborated by the Irish physician James Henry in 1843. The first blind experiment was conducted by the French Royal Commission on Animal Magnetism in 1784 to investigate the claims of mesmerism. An early essay advocating the blinding of researchers came from Claude Bernard in the latter half of the 19th century. Bernard recommended that the observer of an experiment should not have knowledge of the hypothesis being tested. This suggestion contrasted starkly with the prevalent Enlightenment-era attitude that scientific observation can only be objectively valid when undertaken by a well-educated, informed scientist. The first study recorded to have a blinded researcher was published in 1907 by W. H. R. Rivers and H. N. Webber to investigate the effects of caffeine.

Randomized experiments first appeared in psychology, where they were introduced by Charles Sanders Peirce and Joseph Jastrow in the 1880s, and in education. The earliest experiments comparing treatment and control groups were published by Robert Woodworth and Edward Thorndike in 1901, and by John E. Coover and Frank Angell in 1907.

In the early 20th century, randomized experiments appeared in agriculture, due to Jerzy Neyman and Ronald A. Fisher. Fisher's experimental research and his writings popularized randomized experiments.

The first published Randomized Controlled Trial in medicine appeared in the 1948 paper entitled "Streptomycin treatment of pulmonary tuberculosis", which described a Medical Research Council investigation. One of the authors of that paper was Austin Bradford Hill, who is credited as having conceived the modern RCT.

Trial design was further influenced by the large-scale ISIS trials on heart attack treatments that were conducted in the 1980s.

By the late 20th century, RCTs were recognized as the standard method for "rational therapeutics" in medicine.  As of 2004, more than 150,000 RCTs were in the Cochrane Library. Determining the amount of information required to ensure informed consent can be difficult, and further research is necessary to determine the prevalence of and ways to address therapeutic misconception. "Collective equipoise" may also conflict with a lack of personal equipoise (i.e., a personal belief that an intervention is effective), including that of the patient. While some randomisation approaches have been used to minimize the risk that patients are exposed to less effective treatment, such as randomising patients with unequal rates, or adapting the rates during the trial's duration based on outcomes, these solutions have been criticized for raising more ethical problems than they resolve. For example, patients with terminal illness may join trials in the hope of being cured, even when treatments are unlikely to be successful.

Trial registration

In 2004, the International Committee of Medical Journal Editors (ICMJE) announced that all trials starting enrolment after July 1, 2005, must be registered prior to consideration for publication in one of the 12 member journals of the committee. However, trial registration may still occur late or not at all.

Medical journals have been slow in adapting policies requiring mandatory clinical trial registration as a prerequisite for publication.

Classifications

By study design

One way to classify RCTs is by study design.  From most to least common in the healthcare literature, the major categories of RCT study designs are:

Parallel-group – each participant is randomly assigned to a group, and all the participants in the group receive (or do not receive) an intervention.

Crossover – over time, each participant receives (or does not receive) an intervention in a random sequence.

Stepped-wedge trial - " involves random and sequential crossover of clusters (of subjects) from control to intervention until all clusters are exposed." In the past, this design has been called a "waiting list designs" or "phased implementations."

Factorial – each participant is randomly assigned to a group that receives a particular combination of interventions or non-interventions (e.g., group 1 receives vitamin X and vitamin Y, group 2 receives vitamin X and placebo Y, group 3 receives placebo X and vitamin Y, and group 4 receives placebo X and placebo Y).

An analysis of the 616 RCTs indexed in PubMed during December 2006 found that 78% were parallel-group trials, 16% were crossover, 2% were split-body, 2% were cluster, and 2% were factorial. Explanatory RCTs test efficacy in a research setting with highly selected participants and under highly controlled conditions. Most RCTs are superiority trials, in which one intervention is hypothesized to be superior to another in a statistically significant way.

"It eliminates bias in treatment assignment," specifically selection bias and confounding.

"It facilitates blinding (masking) of the identity of treatments from investigators, participants, and assessors."

"It permits the use of probability theory to express the likelihood that any difference in outcome between treatment groups merely indicates chance."

There are two processes involved in randomizing patients to different interventions. First is choosing a randomization procedure to generate an unpredictable sequence of allocations; this may be a simple random assignment of patients to any of the groups at equal probabilities, may be "restricted", or may be "adaptive." A second and more practical issue is allocation concealment, which refers to the stringent precautions taken to ensure that the group assignment of patients are not revealed prior to definitively allocating them to their respective groups. Non-random "systematic" methods of group assignment, such as alternating subjects between one group and the other, can cause "limitless contamination possibilities" and can cause a breach of allocation concealment.

Procedures

The treatment allocation is the desired proportion of patients in each treatment arm.

An ideal randomization procedure would achieve the following goals:

Maximize statistical power, especially in subgroup analyses.  Generally, equal group sizes maximize statistical power, however, unequal groups sizes may be more powerful for some analyses (e.g., multiple comparisons of placebo versus several doses using Dunnett's procedure ), and are sometimes desired for non-analytic reasons (e.g., patients may be more motivated to enroll if there is a higher chance of getting the test treatment, or regulatory agencies may require a minimum number of patients exposed to treatment).

Minimize selection bias.  This may occur if investigators can consciously or unconsciously preferentially enroll patients between treatment arms.  A good randomization procedure will be unpredictable so that investigators cannot guess the next subject's group assignment based on prior treatment assignments. The risk of selection bias is highest when previous treatment assignments are known (as in unblinded studies) or can be guessed (perhaps if a drug has distinctive side effects).

Minimize allocation bias (or confounding).  This may occur when covariates that affect the outcome are not equally distributed between treatment groups, and the treatment effect is confounded with the effect of the covariates (i.e., an "accidental bias").  If the randomization procedure causes an imbalance in covariates related to the outcome across groups, estimates of effect may be biased if not adjusted for the covariates (which may be unmeasured and therefore impossible to adjust for).

However, no single randomization procedure meets those goals in every circumstance, so researchers must select a procedure for a given study based on its advantages and disadvantages.

Simple

This is a commonly used and intuitive procedure, similar to "repeated fair coin-tossing."

Restricted

To balance group sizes in smaller RCTs, some form of "restricted" randomization is recommended.

Allocation concealment

"Allocation concealment" (defined as "the procedure for protecting the randomization process so that the treatment to be allocated is not known before the patient is entered into the study") is important in RCTs. In practice, clinical investigators in RCTs often find it difficult to maintain impartiality. Stories abound of investigators holding up sealed envelopes to lights or ransacking offices to determine group assignments in order to dictate the assignment of their next patient. Such practices introduce selection bias and confounders (both of which should be minimized by randomization), possibly distorting the results of the study. On the other hand, a 2008 study of 146 meta-analyses concluded that the results of RCTs with inadequate or unclear allocation concealment tended to be biased toward beneficial effects only if the RCTs' outcomes were subjective as opposed to objective.

Sample size

The number of treatment units (subjects or groups of subjects) assigned to control and treatment groups, affects an RCT's reliability. If the effect of the treatment is small, the number of treatment units in either group may be insufficient for rejecting the null hypothesis in the respective statistical test. The failure to reject the null hypothesis would imply that the treatment shows no statistically significant effect on the treated in a given test. But as the sample size increases, the same RCT may be able to demonstrate a significant effect of the treatment, even if this effect is small.

Blinding

An RCT may be blinded, (also called "masked") by "procedures that prevent study participants, caregivers, or outcome assessors from knowing which intervention was received."  The 2010 CONSORT Statement specifies that authors and editors should not use the terms "single-blind", "double-blind", and "triple-blind"; instead, reports of blinded RCT should discuss "If done, who was blinded after assignment to interventions (for example, participants, care providers, those assessing outcomes) and how." "open", or (if the intervention is a medication) "open-label". In 2008 a study concluded that the results of unblinded RCTs tended to be biased toward beneficial effects only if the RCTs' outcomes were subjective as opposed to objective; In pragmatic RCTs, although the participants and providers are often unblinded, it is "still desirable and often possible to blind the assessor or obtain an objective source of data for evaluation of outcomes.") and other methods can be used.

For continuous outcome data, analysis of covariance (e.g., for changes in blood lipid levels after receipt of atorvastatin after acute coronary syndrome) tests the effects of predictor variables.

For time-to-event outcome data that may be censored, survival analysis (e.g., Kaplan–Meier estimators and Cox proportional hazards models for time to coronary heart disease after receipt of hormone replacement therapy in menopause) is appropriate.

Regardless of the statistical methods used, important considerations in the analysis of RCT data include:

Whether an RCT should be stopped early due to interim results.  For example, RCTs may be stopped early if an intervention produces "larger than expected benefit or harm", or if "investigators find evidence of no important difference between experimental and control interventions." when some outcome data are missing, options include analyzing only cases with known outcomes and using imputed data. The CONSORT 2010 checklist contains 25 items (many with sub-items) focusing on "individually randomised, two group, parallel trials" which are the most common type of RCT.

Consort 2010 Statement: Non-Pharmacologic Treatment Interventions

"Reporting of surrogate endpoints in randomised controlled trial reports (CONSORT-Surrogate): extension checklist with explanation and elaboration"

Relative importance and observational studies

Two studies published in The New England Journal of Medicine in 2000 found that observational studies and RCTs overall produced similar results. The authors of the 2000 findings questioned the belief that "observational studies should not be used for defining evidence-based medical care" and that RCTs' results are "evidence of the highest grade." According to a 2014 (updated in 2024) Cochrane review, there is little evidence for significant effect differences between observational studies and randomized controlled trials.  To evaluate differences it is necessary to consider things other than design, such as heterogeneity, population, intervention or comparator.

RCTs may be unnecessary for treatments that have dramatic and rapid effects relative to the expected stable or progressively worse natural course of the condition treated. One example is combination chemotherapy including cisplatin for metastatic testicular cancer, which increased the cure rate from 5% to 60% in a 1977 non-randomized study.

Interpretation of statistical results

Like all statistical methods, RCTs are subject to both type I ("false positive") and type II ("false negative") statistical errors.  Regarding Type I errors, a typical RCT will use 0.05 (i.e., 1 in 20) as the probability that the RCT will falsely find two equally effective treatments significantly different. Regarding Type II errors, despite the publication of a 1978 paper noting that the sample sizes of many "negative" RCTs were too small to make definitive conclusions about the negative results, by 2005-2006 a sizeable proportion of RCTs still had inaccurate or incompletely reported sample size calculations.

Peer review

Peer review of results is an important part of the scientific method. Reviewers examine the study results for potential problems with design that could lead to unreliable results (for example by creating a systematic bias), evaluate the study in the context of related studies and other evidence, and evaluate whether the study can be reasonably considered to have proven its conclusions. To underscore the need for peer review and the danger of overgeneralizing conclusions, two Boston-area medical researchers performed a randomized controlled trial in which they randomly assigned either a parachute or an empty backpack to 23 volunteers who jumped from either a biplane or a helicopter. The study was able to accurately report that parachutes fail to reduce injury compared to empty backpacks. The key context that limited the general applicability of this conclusion was that the aircraft were parked on the ground, and participants had only jumped about two feet.

Advantages

RCTs are considered to be the most reliable form of scientific evidence in the hierarchy of evidence that influences healthcare policy and practice because RCTs reduce spurious causality and bias. Results of RCTs may be combined in systematic reviews which are increasingly being used in the conduct of evidence-based practice. Some examples of scientific organizations' considering RCTs or systematic reviews of RCTs to be the highest-quality evidence available are:

As of 1998, the National Health and Medical Research Council of Australia designated "Level I" evidence as that "obtained from a systematic review of all relevant randomised controlled trials" and "Level II" evidence as that "obtained from at least one properly designed randomised controlled trial."

Since at least 2001, in making clinical practice guideline recommendations the United States Preventive Services Task Force has considered both a study's design and its internal validity as indicators of its quality. It has recognized "evidence obtained from at least one properly randomized controlled trial" with good internal validity (i.e., a rating of "I-good") as the highest quality evidence available to it.

For issues involving "Therapy/Prevention, Aetiology/Harm", the Oxford Centre for Evidence-based Medicine as of 2011 defined "Level 1a" evidence as a systematic review of RCTs that are consistent with each other, and "Level 1b" evidence as an "individual RCT (with narrow Confidence Interval)."

Notable RCTs with unexpected results that contributed to changes in clinical practice include:

After Food and Drug Administration approval, the antiarrhythmic agents flecainide and encainide came to market in 1986 and 1987 respectively. The non-randomized studies concerning the drugs were characterized as "glowing", and their sales increased to a combined total of approximately 165,000 prescriptions per month in early 1989.  Sales of the drugs then decreased.  Possible explanations for the discrepancy between the observational studies and the RCTs involved differences in methodology, in the hormone regimens used, and in the populations studied. The use of hormone replacement therapy decreased after publication of the RCTs.

Disadvantages

Many papers discuss the disadvantages of RCTs.   Among the most frequently cited drawbacks are:

Time and costs

RCTs can be expensive; for a mean cost of US$12 million per RCT.  Nevertheless, the return on investment of RCTs may be high, in that the same study projected that the 28 RCTs produced a "net benefit to society at 10-years" of 46 times the cost of the trials program, based on evaluating a quality-adjusted life year as equal to the prevailing mean per capita gross domestic product.

It is costly to maintain RCTs for the years or decades that would be ideal for evaluating some interventions.

Some RCTs are fully or partly funded by the health care industry (e.g., the pharmaceutical industry) as opposed to government, nonprofit, or other sources. A systematic review published in 2003 found four 1986–2002 articles comparing industry-sponsored and nonindustry-sponsored RCTs, and in all the articles there was a correlation of industry sponsorship and positive study outcome. A 2004 study of 1999–2001 RCTs published in leading medical and surgical journals determined that industry-funded RCTs "are more likely to be associated with statistically significant pro-industry findings." These results have been mirrored in trials in surgery, where although industry funding did not affect the rate of trial discontinuation it was however associated with a lower odds of publication for completed trials. One possible reason for the pro-industry results in industry-funded published RCTs is publication bias.

Ethics and feasibility

Whilst RCTs are considered the golden standard of research in evidence-based medicine, they may be inappropriate for study in certain contexts. For instance, RCTs may be imporper for studying medical interventions with "obvious" benefits to patients, and the evident physiological impacts of surgery may compromise blinding on the part of the subjects without the use of sham controls, which are only considered possible for a narrow range of surgical interventions.

RCTs may also be considered infeasible or unethical for studying the mental health impacts of interventions with obvious physical effects, especially when those are highly sought out by patients, such as with abortion and adolescent transgender healthcare. Other than compromising masking, it is likely that RCT study designs for some of these interventions would also result in high likelihood of withdrawal, non-adherence, and response bias in the control groups, making RCTs potentially unreliable. Similarly, many economists have found RCTs are the gold standard for ensuring outcomes represent causal inference and not just correlation. Overall, the adaptation of RCTs into social science has become significant in recent decades.

Economics

RCTs have become a staple of identifying causal inference among microeconomic studies, particularly in development economics. In 1994, Paul Glewwe, eventual Nobel Prize winner, Michael Kremer, and Sylvie Moulin started one of the earliest RCTs in an economic setting by conducting a long run intervention in a school in Kenya, publishing the results fifteen years later. Three years later in 1997, the largest field experiment in a developing context, the PROGRESA program in Mexico, was studied by a multitude of economic researchers. The impact of RCTs on the discipline has only grown, as economists have found this method as a first-best approach to causal inference identification. While not at the forefront, the use of RCTs has helped to bolster the credibility revolution in empirical microeconomics, as well as becoming popularized as a result of the need for more rigorous identification.

Despite the shift towards using RCTs in research, there still remains division between economists on its use. RCTs also offer the advantage of providing true observational data that can be used where the absence of data would make it difficult to build a causal model with.

The American Economic Association maintains a registry of all active and completed RCTs within the discipline. The registry is free to use and is designed to ensure researchers may share information with regard to on-going field work, as well as failures or limitations of study settings. Since its founding in 2013, the AEA has tracked over 7,400 field experiments across 100 countries, with annual RCT registries growing year over year.

Transport science

Researchers in transport science argue that public spending on programmes such as school travel plans could not be justified unless their efficacy is demonstrated by randomized controlled trials. Graham-Rowe and colleagues  reviewed 77 evaluations of transport interventions found in the literature, categorising them into 5 "quality levels".  They concluded that most of the studies were of low quality and advocated the use of randomized controlled trials wherever possible in future transport research.

Dr. Steve Melia took issue with these conclusions, arguing that claims about the advantages of RCTs, in establishing causality and avoiding bias, have been exaggerated.  He proposed the following eight criteria for the use of RCTs in contexts where interventions must change human behaviour to be effective:

The intervention:

Has not been applied to all members of a unique group of people (e.g. the population of a whole country, all employees of a unique organisation etc.)

Is applied in a context or setting similar to that which applies to the control group

Can be isolated from other activities—and the purpose of the study is to assess this isolated effect

Has a short timescale between its implementation and maturity of its effects

And the causal mechanisms:

Are either known to the researchers, or else all possible alternatives can be tested

Do not involve significant feedback mechanisms between the intervention group and external environments

Have a stable and predictable relationship to exogenous factors

Would act in the same way if the control group and intervention group were reversed

Criminology

A 2005 review found 83 randomized experiments in criminology published in 1982–2004, compared with only 35 published in 1957–1981. The authors classified the studies they found into five categories: "policing", "prevention", "corrections", "court", and "community".

Education

RCTs have been used in evaluating a number of educational interventions. Between 1980 and 2016, over 1,000 reports of RCTs have been published. For example, a 2009 study randomized 260 elementary school teachers' classrooms to receive or not receive a program of behavioral screening, classroom intervention, and parent training, and then measured the behavioral and academic performance of their students. Another 2009 study randomized classrooms for 678 first-grade children to receive a classroom-centered intervention, a parent-centered intervention, or no intervention, and then followed their academic outcomes through age 19.

Criticism

A 2018 review of the 10 most cited randomised controlled trials noted poor distribution of background traits, difficulties with blinding, and discussed other assumptions and biases inherent in randomised controlled trials. These include the "unique time period assessment bias", the "background traits remain constant assumption", the "average treatment effects limitation", the "simple treatment at the individual level limitation", the "all preconditions are fully met assumption", the "quantitative variable limitation" and the "placebo only or conventional treatment only limitation".

See also

Drug development

Hypothesis testing

Impact evaluation

Jadad scale

Pipeline planning

Patient and public involvement

Observational study

Blinded experiment

Statistical inference

References

Further reading

Category:Clinical research

Category:Epidemiological study projects

Category:Evidence-based practices

Category:Design of experiments

Category:Causal inference

Category:Experiments

Category:Research methods