Class activation mapping methods are explainable AI (XAI) techniques used to visualize the regions of an input image that are the most relevant for a particular task, especially image classification, in convolutional neural networks (CNNs). These methods generate heatmaps by weighting the feature maps from a convolutional layer according to their relevance to the target class. machine learning and deep learning were created. They both use statistical and computational methods to learn patterns from data, reducing the need for manually coded rules.

Deep learning is a subfield of machine learning, based on the concept of successive layers of representation, in which the data is progressively unfolded in different ways, to extract relevant and informative patterns in data analysis. Deep learning algorithms are defined as feature learning algorithms automatically learning hierarchical feature representations from raw data, extracting increasingly abstract features through multiple layers.

CNNs (and deep learning models more broadly) are described as black boxes due to their complex and non-transparent internal layers of representation. The need for clearer indications on its internal working and decision-making process gave birth to XAI techniques. image captioning, visual question answering and image segmentation. and it generalizes the deconvnet method by Zeiler and Fergus.

Class model visualization synthesizes an artificial input image that strongly activates the output neurons associated with a target class. Given a trained, fixed model, this method starts with a zero-initialized image, backpropagates the gradients from the class score to the image pixels, updates the image pixels increasing the specific class scores and it repeats the pixel updating process, showing an encoded (idealized version) prototype of the class of interest.

Guided backpropagation

The concept of guided backpropagation can be traced for the first time in the paper by Springenberg et al. "Striving For Simplicity: The All Convolutional Net"  and also this method builds upon the work by Zeiler and Fergus "Visualizing and Understanding Convolutional Networks".

Base versions

Class activation mapping and gradient-weighted class activation mapping are the original and most widely used methods for visual explanations in convolutional neural networks. These methods serve as the foundation for many later developments in explainable AI.

Notation: In this article, the symbols i and j represent integer indices that disappear inside sums or averages, while x and y are the continuous (or up-sampled integer) coordinates of the final heat-map that is plotted.

Class activation mapping (CAM)

Class activation mapping (CAM) was the first, and the original, version of CAM methods, and it gave the name to the whole category. The approach was firstly introduced by Zhou et al. in their seminal work "Learning Deep Features for Discriminative Localization".

Global average pooling (GAP)

Global average pooling (GAP) represents the key element in the original CAM approach.

It is a dimensionality reduction technique and, similarly to other pooling layers, it allows the downsampling of the feature maps, calculating representative values for a specific region of the feature map. The particularity of GAP is that it calculates a single value for an entire feature map, significantly reducing the model dimensions.

Mathematical description

Considering:

y^C the logits (i.e. the pre-softmax activated neurons responsible for a certain class prediction) of interest;

A^k the feature activated map for a specific convolutional layer;

L^C_{\text{Grad-CAM}} ∈ \mathbb{R}^{u \times v} the class-discriminative localization map, of width u and height v for any class c;

Grad-CAM, employing backpropagation, computes the logit gradient with respect to the feature map A^k as

\frac{\partial{y^C}}{\partial{A^k}(i,j)}

highlighting the importance of a certain class discrimination decision process of the logit.

These gradients are global-average-pooled over each element of the feature map (hence, highlighting the "importance" of the elements of a feature map k for a target class C):

\alpha_k^C = \frac{1}{uv} \sum_{i} \sum_{j} \frac{\partial{y^C}}{\partial{A^k}(i,j)}

So, to account for the total number of feature maps, each of them is multiplied by its weight (via dot-product) and element-wise summation is done:

\sum_k \alpha_k^C A^k

It can be observed that, due to the intrinsic nature of the gradient operation, some elements of the weighted feature map will have negative value, so, since only elements that have increased the logit of the predicted class are of interest, a ReLU activation function is applied:

L_{Grad-CAM}^C(x,y) = ReLU(\sum_k \alpha_k^C A^k(x,y))

Lastly, the output heatmap image dimensions are upsampled to the original image size to match the input dimensions.

Notation: (a,b) indexes all pixel positions in the feature‐map, exactly like (i,j) does, but for the summation in the denominator.

Score-CAM

Score-CAM is a gradient-free CAM technique, thus redefining the original Grad-CAM and Grad-CAM++ working principles. It uses the model confidence scores instead of gradients.

Score-CAM performs the following operations:

Extracts the feature maps A_k of the final convolutional layers, as in the original Grad-CAM;

Upsamples each activation map A_k to the same input image dimensions, defining a mask M_k and each mask is normalized;

Multiplies the original input image by the mask, defining a masked image X'_k = M_k \odot X (\odot is the element-wise multiplication);

Gets a confidence score (a softmax probability is the output value after the softmax operation; the logit is the value before the softmax) for the masked images X'_k, by feeding it into the CNN (either the soft-max probability or the raw logit can be used; both yield similar results in practice);

Considers that confidence score as the weight w_k^c for the feature map A_k.

These operations allow to replace the gradient calculations with the actual model outputs, building more accurate heatmaps.

Mathematically, the localization map is defined as:

L_{Score-CAM}^C(x,y) = ReLU(\sum_k w_k^c A_k(x,y))

and the coefficient w_k^C s:

w_k^C = softmax_{k}(y^C(X'_k)) = \frac{exp(y^C(X'_k))}{\sum_m exp(y^C(X'_m))}

where A_k(x,y) is the activation of channel k  at location (x,y), y^C(X) is the logit for class C for an input X and M_k is the mask, defined as:

M_k(x,y) = \frac{U(A_k)(x,y)-min_{x,y} U(A_m)}{max_{x,y} U(A_k) - min_{x,y} U(A_k)}

with U as the upsampling operation.

Since the process of score calculation is repeated for every channel, Score-CAM is slow with respect to gradient-based methods. Moreover, it focuses on regions highlighted by individual feature maps, ignoring the context of the full image, reducing interpretability in complex scenes.

LayerCAM

LayerCAM enhances backwards class-specific gradients using both intermediate and final convolutional layers. Combining information across layers allows to achieve higher resolution and more fine-grained detail, improving localization.

Specifically, for each position in the feature map, LayerCAM evaluates the gradient. The positive gradients are employed as the weights, w_k^C. Namely:

w_k^C(x,y) = ReLU(\frac{\partial y^C}{\partial A_k(i,j)}(x,y))

The activations are then weighted, and the final class activation map is retrieved by summing over the channels.

L_{Layer-CAM}^C(x,y) = ReLU(\sum_k w_k^C(x,y) A_k(x,y))

This technique offers high-resolution heatmaps, flexible localization and per-location precision, employing positive gradients.

References

External links

Category:Computer vision

Category:Image processing

Category:Neural network architectures

Category:Artificial intelligence