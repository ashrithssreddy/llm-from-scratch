LTX-2 is an open-source artificial intelligence video foundation model released by Lightricks in October 2025. It creates videos based on user prompts and was preceded by LTX Video, which was released in 2024 as the company's first text-to-video model.

History

Origins: LTX Video (2024–2025)

In November 2024 Lightricks publicly released its first text-to-video model, LTX Video. It was a 2-billion parameter model, available as open source.

In May 2025 Lightricks launched LTXV-13b, a version with 13-billion parameters. Two months later, the model broke the 60 second barrier for generated video.

Release of LTX-2 (2025)

In October 2025 Lightricks announced its latest model, and renamed it LTX-2. The model was described as capable of generating synchronized audio and video at native 4K resolution and up to 50 frames per second (fps), using a variety of conditions and prompts, including text-to-video and image-to-video.

Google highlighted the fact that LTX-2 was trained on its infrastructure, and saying it was "The first open source AI video generation model, powered by Google Cloud".

Upon its release it was ranked in the top-3 models for image-to-video creation by Artificial Analysis, behind Kling 3.5 by Kling AI and Veo 3.1 by Google. Its text-to-image option was ranked 7th

Technical features

Advancements over LTX Video

LTX-2 builds upon the LTX Video architecture with several major improvements:

Unified audio-video generation producing synchronized dialogue, ambience, and motion

Native 4K rendering

50-fps output for cinematic motion

Three operational modes (Fast, Pro, Ultra)

More efficient diffusion pipelines enabling high fidelity on consumer GPUs

Core capabilities

Text-to-video generation

Image-to-video generation

Multimodal audiovisual synthesis

High-resolution spatial and temporal coherence

Configurable quality/performance settings

Open-source distribution of weights and datasets

Reception

Initial reception to LTX-2 was broadly positive, with several technology and media outlets highlighting its open-source approach and multimodal capabilities.

AI News characterized LTX-2 as a “major step forward in the democratization of cinematic-quality video generation,” praising its consumer-grade hardware efficiency and multi-tier generation modes, while also noting ongoing challenges in long-form temporal stability.

Some early reviewers also pointed out quality limitations. The Ray3 technical review noted occasional inconsistencies in lip-sync and motion tracking during long scenes, though it stated these were “in line with the challenges faced by all current AI video diffusion models” and expected to improve with continued iteration.

See also

Sora (text-to-video model)

Veo (text-to-video model)

Generative artificial intelligence

References

External links

Official Documentation of LTX-2

Official Github Repo

Category:Articles containing video clips

Category:Applications of artificial intelligence

Category:2024 software

Category:Video processing

Category:Film and video technology

Category:Text-to-video generation

Category:Generative artificial intelligence

Category:2024 in artificial intelligence

Category:2025 in artificial intelligence