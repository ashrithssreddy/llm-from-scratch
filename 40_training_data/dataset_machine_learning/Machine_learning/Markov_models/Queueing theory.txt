are systems in which single queues are connected by a routing network. In this image, servers are represented by circles, queues by a series of rectangles and the routing network by arrows. In the study of queue networks one typically tries to obtain the equilibrium distribution of the network, although in many applications the study of the transient state is fundamental.]]

Queueing theory is the mathematical study of waiting lines, or queues. A queueing model is constructed so that queue lengths and waiting time can be predicted. project management, and particularly industrial engineering, where they are applied in the design of factories, shops, offices, and hospitals.

Spelling

The spelling "queueing" over "queuing" is typically encountered in the academic research field. In fact, one of the flagship journals of the field is Queueing Systems.

Description

Queueing theory is one of the major areas of study in the discipline of management science. Through management science, businesses are able to solve a variety of problems using different scientific and mathematical approaches. Queueing analysis is the probabilistic analysis of waiting lines, and thus the results, also referred to as the operating characteristics, are probabilistic rather than deterministic. The probability that n customers are in the queueing system, the average number of customers in the queueing system, the average number of customers in the waiting line, the average time spent by a customer in the total queuing system, the average time spent by a customer in the waiting line, and finally the probability that the server is busy or idle are all of the different operating characteristics that these queueing models compute. For an example of the notation, the M/M/1 queue is a simple model where a single server serves jobs that arrive according to a Poisson process (where inter-arrival durations are exponentially distributed) and have exponentially distributed service times (the M denotes a Markov process). In an M/G/1 queue, the G stands for "general" and indicates an arbitrary probability distribution for service times.

Example analysis of an M/M/1 queue

Consider a queue with one server and the following characteristics:

\lambda: the arrival rate (the reciprocal of the expected time between each customer arriving, e.g. 10 customers per second)

\mu: the reciprocal of the mean service time (the expected number of consecutive service completions per the same unit time, e.g. per 30 seconds)

n: the parameter characterizing the number of customers in the system

P_n: the probability of there being n customers in the system in steady state

Further, let E_n represent the number of times the system enters state n, and L_n represent the number of times the system leaves state n. Then \left\vert E_n - L_n \right\vert \in \{0, 1\} for all n. That is, the number of times the system leaves a state differs by at most 1 from the number of times it enters that state, since it will either return into that state at some time in the future (E_n = L_n) or not (\left\vert E_n - L_n \right\vert = 1).

When the system arrives at a steady state, the arrival rate should be equal to the departure rate.

Thus the balance equations

\mu P_1 = \lambda P_0

\lambda P_0 + \mu P_2 = (\lambda + \mu) P_1

\lambda P_{n-1} + \mu P_{n+1} = (\lambda + \mu) P_n

imply

P_n = \frac{\lambda}{\mu} P_{n-1},\ n=1,2,\ldots

The fact that P_0 + P_1 + \cdots = 1 leads to the geometric distribution formula

P_n = (1 - \rho) \rho^n

where \rho = \frac{\lambda}{\mu} .

Simple two-equation queue

A common basic queueing system is attributed to Erlang and is a modification of Little's Law. Given an arrival rate λ, a dropout rate σ, and a departure rate μ, length of the queue L is defined as:

L = \frac{\lambda - \sigma}{\mu}.

Assuming an exponential distribution for the rates, the waiting time W can be defined as the proportion of arrivals that are served. This is equal to the exponential survival rate of those who do not drop out over the waiting period, giving:

\frac{\mu}{\lambda} = e^{-W{\mu}}

The second equation is commonly rewritten as:

W = \frac{1}{\mu} \mathrm{ln}\frac{\lambda}{\mu}

The two-stage one-box model is common in epidemiology.

History

In 1909, Agner Krarup Erlang, a Danish engineer who worked for the Copenhagen Telephone Exchange, published the first paper on what would now be called queueing theory. He modeled the number of telephone calls arriving at an exchange by a Poisson process and solved the M/D/1 queue in 1917 and M/D/k queueing model in 1920. In Kendall's notation:

M stands for "Markov" or "memoryless", and means arrivals occur according to a Poisson process

D stands for "deterministic", and means jobs arriving at the queue require a fixed amount of service

k describes the number of servers at the queueing node (k = 1, 2, 3, ...)

If the node has more jobs than servers, then jobs will queue and wait for service.

The M/G/1 queue was solved by Felix Pollaczek in 1930, a solution later recast in probabilistic terms by Aleksandr Khinchin and now known as the Pollaczek–Khinchine formula. In 1953, David George Kendall solved the GI/M/k queue and introduced the modern notation for queues, now known as Kendall's notation. In 1957, Pollaczek studied the GI/G/1 using an integral equation. John Kingman gave a formula for the mean waiting time in a G/G/1 queue, now known as Kingman's formula.

Leonard Kleinrock worked on the application of queueing theory to message switching in the early 1960s and packet switching in the early 1970s. His initial contribution to this field was his doctoral thesis at the Massachusetts Institute of Technology in 1962, published in book form in 1964. His theoretical work published in the early 1970s underpinned the use of packet switching in the ARPANET, a forerunner to the Internet.

The matrix geometric method and matrix analytic methods have allowed queues with phase-type distributed inter-arrival and service time distributions to be considered.

Systems with coupled orbits are an important part in queueing theory in the application to wireless networks and signal processing.

Modern day application of queueing theory concerns among other things product development where (material) products have a spatiotemporal existence, in the sense that products have a certain volume and a certain duration.

Problems such as performance metrics for the M/G/k queue remain an open problem. this principle states that customers are served one at a time and that the customer that has been waiting the longest is served first.

Last in, first out: This principle also serves customers one at a time, but the customer with the shortest waiting time will be served first.

Shortest job first: The next job to be served is the one with the smallest size.

Preemptive shortest job first: The next job to be served is the one with the smallest original size.

Shortest remaining processing time: The next job to serve is the one with the smallest remaining processing requirement.

Service facility

Single server: customers line up and there is only one server

Several parallel servers (single queue): customers line up and there are several servers

Several parallel servers (several queues): there are many counters and customers can decide for which to queue

Unreliable server

Server failures occur according to a stochastic (random) process (usually Poisson) and are followed by setup periods during which the server is unavailable. The interrupted customer remains in the service area until server is fixed.

Customer waiting behavior

Balking: customers decide not to join the queue if it is too long

Jockeying: customers switch between queues if they think they will get served faster by doing so

Reneging: customers leave the queue if they have waited too long for service

Arriving customers not served (either due to the queue having no buffer, or due to balking or reneging by the customer) are also known as dropouts. The average rate of dropouts is a significant parameter describing a queue.

Queueing networks

Queue networks are systems in which multiple queues are connected by customer routing. When a customer is serviced at one node, it can join another node and queue for service, or leave the network.

For networks of m nodes, the state of the system can be described by an m–dimensional vector (x1, x2, ..., x'm) where x'i represents the number of customers at each node.

The simplest non-trivial networks of queues are called tandem queues. The first significant results in this area were Jackson networks, for which an efficient product-form stationary distribution exists and the mean value analysis (which allows average metrics such as throughput and sojourn times) can be computed. If the total number of customers in the network remains constant, the network is called a closed network and has been shown to also have a product–form stationary distribution by the Gordon–Newell theorem. This result was extended to the BCMP network, where a network with very general service time, regimes, and customer routing is shown to also exhibit a product–form stationary distribution. The normalizing constant can be calculated with the Buzen's algorithm, proposed in 1973.

Networks of customers have also been investigated, such as Kelly networks, where customers of different classes experience different priority levels at different service nodes. Another type of network are G-networks, first proposed by Erol Gelenbe in 1993: these networks do not assume exponential time distributions like the classic Jackson network.

Routing algorithms

In discrete-time networks where there is a constraint on which service nodes can be active at any time, the max-weight scheduling algorithm chooses a service policy to give optimal throughput in the case that each job visits only a single-person service node.

Mean-field limits

Mean-field models consider the limiting behaviour of the empirical measure (proportion of queues in different states) as the number of queues m approaches infinity. The impact of other queues on any given queue in the network is approximated by a differential equation. The deterministic model converges to the same stationary distribution as the original model.

Heavy traffic/diffusion approximations

In a system with high occupancy rates (utilisation near 1), a heavy traffic approximation can be used to approximate the queueing length process by a reflected Brownian motion, Ornstein–Uhlenbeck process, or more general diffusion process. The number of dimensions of the Brownian process is equal to the number of queueing nodes, with the diffusion restricted to the non-negative orthant.

Fluid limits

Fluid models are continuous deterministic analogs of queueing networks obtained by taking the limit when the process is scaled in time and space, allowing heterogeneous objects. This scaled trajectory converges to a deterministic equation which allows the stability of the system to be proven. It is known that a queueing network can be stable but have an unstable fluid limit.

Queueing Applications

Queueing theory finds widespread application in computer science and information technology. In networking, for instance, queues are integral to routers and switches, where packets queue up for transmission. By applying queueing theory principles, designers can optimize these systems, ensuring responsive performance and efficient resource utilization.

Beyond the technological realm, queueing theory is relevant to everyday experiences. Whether waiting in line at a supermarket or for public transportation, understanding the principles of queueing theory provides valuable insights into optimizing these systems for enhanced user satisfaction. At some point, everyone will be involved in an aspect of queuing. What some may view to be an inconvenience could possibly be the most effective method.

Queueing theory, a discipline rooted in applied mathematics and computer science, is a field dedicated to the study and analysis of queues, or waiting lines, and their implications across a diverse range of applications. This theoretical framework has proven instrumental in understanding and optimizing the efficiency of systems characterized by the presence of queues. The study of queues is essential in contexts such as traffic systems, computer networks, telecommunications, and service operations.

Queueing theory delves into various foundational concepts, with the arrival process and service process being central. The arrival process describes the manner in which entities join the queue over time, often modeled using stochastic processes like Poisson processes. The efficiency of queueing systems is gauged through key performance metrics. These include the average queue length, average wait time, and system throughput. These metrics provide insights into the system's functionality, guiding decisions aimed at enhancing performance and reducing wait times.

See also

Ehrenfest model

Erlang unit

Line management

Network simulation

Project production management

Queue area

Queueing delay

Queue management system

Queuing Rule of Thumb

Random early detection

Renewal theory

Throughput

Scheduling (computing)

Traffic jam

Traffic generation model

Flow network

References

Further reading

Online

chap.15, pp.&nbsp;380–412

Leonard Kleinrock, Information Flow in Large Communication Nets, (MIT, Cambridge, May 31, 1961) Proposal for a Ph.D. Thesis

Leonard Kleinrock. Information Flow in Large Communication Nets (RLE Quarterly Progress Report, July 1961)

Leonard Kleinrock. Communication Nets: Stochastic Message Flow and Delay (McGraw-Hill, New York, 1964)

External links

Teknomo's Queueing theory tutorial and calculators

Virtamo's Queueing Theory Course

Myron Hlynka's Queueing Theory Page

LINE: a general-purpose engine to solve queueing models

Category:Production planning

Category:Customer experience

Category:Operations research

Category:Formal sciences

Category:Rationing

Category:Network performance

Category:Markov models