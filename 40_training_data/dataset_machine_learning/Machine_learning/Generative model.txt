In statistical classification, two main approaches are called the generative approach and the discriminative approach. These compute classifiers by different approaches, differing in the degree of statistical modelling. Terminology is inconsistent,{{efn|Three leading sources, , , and , give different divisions and definitions.}} but three major types can be distinguished:

A generative model is a statistical model of the joint probability distribution P(X, Y) on a given observable variable X and target variable Y; A generative model can be used to "generate" random instances (outcomes) of an observation x.  refers to these three classes as generative learning, conditional learning, and discriminative learning, but  only distinguish two classes, calling them generative classifiers (joint distribution) and discriminative classifiers (conditional distribution or no distribution), not distinguishing between the latter two classes. Analogously, a classifier based on a generative model is a generative classifier, while a classifier based on a discriminative model is a discriminative classifier, though this term also refers to classifiers that are not based on a model.

Standard examples of each, all of which are linear classifiers, are:

generative classifiers:

naive Bayes classifier and

linear discriminant analysis

discriminative model:

logistic regression

In application to classification, one wishes to go from an observation x to a label y (or probability distribution on labels). One can compute this directly, without using a probability distribution (distribution-free classifier); one can estimate the probability of a label given an observation, P(Y|X=x) (discriminative model), and base classification on that; or one can estimate the joint distribution P(X, Y) (generative model), from that compute the conditional probability P(Y|X=x), and then base classification on that. These are increasingly indirect, but increasingly probabilistic, allowing more domain knowledge and probability theory to be applied. In practice different approaches are used, depending on the particular problem, and hybrids can combine strengths of multiple approaches.

Definition

An alternative division defines these symmetrically as:

a generative model is a model of the conditional probability of the observable X, given a target y, symbolically, P(X\mid Y = y)

a discriminative model is a model of the conditional probability of the target Y, given an observation x, symbolically, P(Y\mid X = x)

Regardless of precise definition, the terminology is constitutional because a generative model can be used to "generate" random instances (outcomes), either of an observation and target (x, y), or of an observation x given a target value y,

Despite the fact that discriminative models do not need to model the distribution of the observed variables, they cannot generally express complex relationships between the observed and target variables. But in general, they don't necessarily perform better than generative models at classification and regression tasks. The two classes are seen as complementary or as different views of the same procedure.

Deep generative models

With the rise of deep learning, a new family of methods, called deep generative models (DGMs), is formed through the combination of generative models and deep neural networks. An increase in the scale of the neural networks is typically accompanied by an increase in the scale of the training data, both of which are required for good performance.

Popular DGMs include variational autoencoders (VAEs), generative adversarial networks (GANs), and auto-regressive models. Recently, there has been a trend to build very large deep generative models. are auto-regressive neural language models that contain billions of parameters, BigGAN and VQ-VAE which are used for image generation that can have hundreds of millions of parameters, and Jukebox is a very large generative model for musical audio that contains billions of parameters.

Types

Generative models

Types of generative models are:

Gaussian mixture model (and other types of mixture model)

Hidden Markov model

Probabilistic context-free grammar

Bayesian network (e.g. Naive bayes, Autoregressive model)

Averaged one-dependence estimators

Latent Dirichlet allocation

Boltzmann machine (e.g. Restricted Boltzmann machine, Deep belief network)

Variational autoencoder

Generative adversarial network

Flow-based generative model

Energy based model

Diffusion model

If the observed data are truly sampled from the generative model, then fitting the parameters of the generative model to maximize the data likelihood is a common method. However, since most statistical models are only approximations to the true distribution, if the model's application is to infer about a subset of variables conditional on known values of others, then it can be argued that the approximation makes more assumptions than are necessary to solve the problem at hand. In such cases, it can be more accurate to model the conditional density functions directly using a discriminative model (see below), although application-specific details will ultimately dictate which approach is most suitable in any particular case.

Discriminative models

k-nearest neighbors algorithm

Logistic regression

Support Vector Machines

Decision Tree Learning

Random Forest

Maximum-entropy Markov models

Conditional random fields

Examples

Simple example

Suppose the input data is x \in \{1, 2\}, the set of labels for x is y \in \{0, 1\}, and there are the following 4 data points:

(x,y) = \{(1,0), (1,1), (2,0), (2,1)\}

For the above data, estimating the joint probability distribution p(x,y) from the empirical measure will be the following:

while p(y|x) will be following:

Text generation

gives an example in which a table of frequencies of English word pairs is used to generate a sentence beginning with "representing and speedily is an good"; which is not proper English but which will increasingly approximate it as the table is moved from word pairs to word triplets etc.

See also

Discriminative model

Graphical model

Notes

References

External links

, (mirror, mirror), published as book (above)

Category:Machine learning

Category:Statistical models

Category:Probabilistic models