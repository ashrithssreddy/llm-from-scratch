The wake-sleep algorithm is an unsupervised learning algorithm for deep generative models, especially Helmholtz Machines. The algorithm is similar to the expectation-maximization algorithm, and optimizes the model likelihood for observed data. The name of the algorithm derives from its use of two learning phases, the “wake” phase and the “sleep” phase, which are performed alternately. but is also being applied for machine learning. In a graphical representation of the algorithm, data is applied to the algorithm at the bottom, while higher layers form gradually more abstract representations. Between each pair of layers are two sets of weights: Recognition weights, which define how representations are inferred from data, and generative weights, which define how these representations relate to data.

Training

Training consists of two phases – the “wake” phase and the “sleep” phase. It has been proven that this learning algorithm is convergent. To better approximate the posterior distribution, it is possible to employ importance sampling, with the recognition network as the proposal distribution. This improved approximation of the posterior distribution also improves the overall performance of the model.

See also

Restricted Boltzmann machine, a type of neural net that is trained with a conceptually similar algorithm.

Helmholtz machine, a neural network model trained by the wake-sleep algorithm.

References

Category:Machine learning algorithms