{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c158f40",
   "metadata": {},
   "source": [
    "## Text classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e76981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "my_pipeline = pipeline(\n",
    "    \"text-classification\"\n",
    "    model = \"distilbert-base-uncased-finetuned-sst-2-english\" # todo: how to choose a model?\n",
    ")\n",
    "my_pipeline(\"my wifi is slower than the snail\")\n",
    "[{\"label\":\"negative\", \"score\":0.99}]\n",
    "\n",
    "## e.g. gramatical correctness (labels acceptable or unacceptable)\n",
    "    grammer checkers and Language learning tools\n",
    "my_pipeline = pipeline(\n",
    "    \"text-classification\"\n",
    "    model = \"abdulmatinomotoso/English_Grammar_Checker\" \n",
    ")\n",
    "my_pipeline(\"he eat pizza every daily\")\n",
    "[{\"label\":\"label_0\", \"score\":0.99}]\n",
    "\n",
    "## e.g. QNLI question natural language inference\n",
    "# if the premise answers the question \n",
    "question: which state is hollywood in?\n",
    "Premise: Hollywood in California (True/Entailment) \n",
    "Premise: Hollywood in amazing (False/Not-Entailment) \n",
    "\n",
    "my_pipeline = pipeline(\n",
    "    \"text-classification\"\n",
    "    model = \"cross-encoder/qnli-electra-base\" \n",
    ")\n",
    "my_pipeline(\"which state is hollywood in?, Hollywood in California\")\n",
    "[{\"label\":\"label_0\", \"score\":0.997}]\n",
    "\n",
    "## e.g. Dynamic Category assignment\n",
    "# assign predefined cateogries to text. content mdoeration and recommendation systems\n",
    "my_pipeline = pipeline(\n",
    "    \"zero-shot-classification\"\n",
    "    model = \"facebook/bart-large-mnli\" \n",
    ")\n",
    "my_pipeline(\"hey datacamp, we wanna feature you in newsletter\", [\"sales\",\"marketing\",\"support\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06551020",
   "metadata": {},
   "source": [
    "## Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81352c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractive: large text to small text while retaining key information\n",
    "    legal docs, financial insights\n",
    "abstractive: new text\n",
    "    news articles summary\n",
    "    content recommendations\n",
    "\n",
    "my_pipeline = pipeline(\n",
    "    task = \"summarization\"\n",
    "    model = \"nyamuda/extractive-summarization\" # extractive\n",
    "    -- model = \"sshleifer/distilbart-cnn-12-6\" # abstrative, fabrication risk\n",
    ")\n",
    "output = my_pipeline(\"this is a large text about data science\") # output is dict\n",
    "min_new_tokens and max_new_tokens control for length. todo: how much is 1 token\n",
    "output[0][\"summary_text\"]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d957837",
   "metadata": {},
   "source": [
    "## Auto models and tokenizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2221142",
   "metadata": {},
   "outputs": [],
   "source": [
    "Auto Classes: Pipelines are great but Auto Classes are more flexible to access models and tokenizers\n",
    "    More control than quick-experimentation pipelines\n",
    "\n",
    "AutoModels:\n",
    "from transformers import AutoModelForSequenceClassification # AKA text classification\n",
    "\n",
    "my_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"dilbert-base-uncased-finetuned-sst-2-english\"\n",
    ")\n",
    "\n",
    "Tokenizers: to prepare text input for using in the model\n",
    "    Clean input and split text into tokens\n",
    "    todo: what exactly is token\n",
    "Ideally: choose tokenizer paired with the model itself (happens in pipeline automatically, but manually in autoclasses)\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "tokens = tokenizer.tokenize(\"AI: helping robots think and humans overthink\")\n",
    "print(tokens)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BERT-Base-Cased\")\n",
    "tokens = tokenizer.tokenize(\"AI: helping robots think and humans overthink\")\n",
    "print(tokens) # different output\n",
    "\n",
    "todo: do I need to know all tokenizations?\n",
    "todo: is there a taxonomy of tokenization?\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline \n",
    "my_model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "my_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# todo: what does this line even do? more customization? what other parameters does pipeline() take\n",
    "my_pipeline = pipeline(task = \"sentiment-analysis\", model = my_model, tokenizer = my_tokenizer)\n",
    "\n",
    "# what customization. e.g.\n",
    "task reqiores tokenizing financial reports, adding custom tokens like EBITDA or ROI\n",
    "Our customer support model should prioritize 'Urgent' category more often\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc9f161",
   "metadata": {},
   "source": [
    "## Document Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answering questions from a Document\n",
    "2 inputs: document (pdf) and a question\n",
    "    research doc, legal contract, financial statement etc.  \n",
    "    total revenue of Q3\n",
    "\n",
    "from pypdf import PdfReader\n",
    "reader = PdfReader(\"abc.pdf\")\n",
    "\n",
    "document_text = \"\"\n",
    "for page in reader.pages:\n",
    "    document_text = document_text + page.extract_text()\n",
    "\n",
    "my_pipeline =  pipeline(\n",
    "    task = \"question-answering\" \n",
    "    model = \"distilbert-base-cased-distilled-squad\"\n",
    ")\n",
    "my_question = \"how many\"\n",
    "results = my_pipeline(question = my_question, context = document_text)  \n",
    "results[\"answer\"]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b0b9cb",
   "metadata": {},
   "source": [
    "## Scratch Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6066ce1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
